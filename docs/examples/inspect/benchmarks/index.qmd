---
title: "Benchmarks"
subtitle: "Data: [benchmarks.parquet](benchmarks.parquet)"
resources:
   - benchmarks.py
---

This example plots several benchmarks against models from various organizations, with release date on the x-axis. The original data for this plot was published by the [Epoch AI Benchmarking Hub](https://epoch.ai/data/ai-benchmarking-dashboard).

```{python}
#| filename: Code

from inspect_viz import Data, Selection
from inspect_viz.input import checkbox_group, select
from inspect_viz.layout import vconcat, vspace
from inspect_viz.plot import plot, legend
from inspect_viz.mark import dot, rule_x
from inspect_viz.table import table
from inspect_viz.transform import sql

# read data
benchmarks = Data.from_file("benchmarks.parquet") # <1>

# provide explicit sequence of org names
orgs = ["OpenAI", "Anthropic", "Google", "Meta AI", "xAI", "Mistral AI"] 

# compute confidence interval value
def ci_value(direction):  # <2>
    Z_ALPHA = 1.960
    return sql(
        "score" +
        f"{direction}" +
        f"({Z_ALPHA} * stderr)"
    )  # <2>

vconcat(
    # select benchmark
    select(benchmarks, label="Benchmark: ", column="benchmark", value="GPQA Diamond", width=370),
    
    # filter models by organization(s)
    checkbox_group(benchmarks, column="organization", options=orgs),
    
    # dot plot w/ error bars
    vspace(15),
    plot(
        dot(
            benchmarks,
            x="release_date",
            y="score",
            r=3,
            fill="organization",
            channels= {  # <3>
                "Model": "model", 
                "Scorer": "scorer", 
                "Stderr": "stderr",
                "Log Viewer": "log_viewer"
            } # <3>
        ),
        rule_x( 
            benchmarks,
            x="release_date",
            y="score",
            y1=ci_value("-"),  # <4>
            y2=ci_value("+"),
            stroke="organization",
            stroke_opacity=0.4, # <4>
            marker="tick-x",
        ), 
        legend=legend("color", target=benchmarks.selection), # <5>
        x_domain="fixed",  # <6>
        y_domain=[0,1.0],  # <6>
        color_domain=orgs, 
        x_label="Release Date",
        y_label="Score",
        color_label="Organization"
    )
)
```

1. Benchmark data sourced from [Epoch AI](https://epoch.ai/data/ai-benchmarking-dashboard) and prepared with [benchmark.py](benchmarks.py).

2. Function to dynamically compute confidence intervals using the `sql()` function.

3. Additional channels are added to the tooltip.

4. Confidence interval: compute dynamically using `ci_value()`, color by organization, and reduce opacity.

5. Specifying `target` makes the legend clickable.

6. Domains: `x_domain` fixed so that the axes don't jump around for organization selections; `y_domain` should always span up to 1.0.



