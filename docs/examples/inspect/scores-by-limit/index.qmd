---
title: "Tool Calls"
subtitle: "Dataset: [swebench_token_limit.parquet](swebench_token_limit.parquet)"
---


This example illustrates the code behind the [`scores_by_limit()`](../../../view-scores-by-limit.qmd) pre‑built view function. If you want to include this plot in your notebooks or sites, start with that function rather than the lower‑level code below.

The plot shows how model **success rate** changes as the **compute budget** increases (e.g., token limit, messages, cost, or time). It helps answer “*Will performance keep improving if I spend more?*”. The shaded band displays the confidence interval derived from the standard error.


```{python}
#| filename: Code

from inspect_viz import Data, Selection
from inspect_viz.mark import area_y, line
from inspect_viz.plot import plot, legend
from inspect_viz.transform import sql
from inspect_viz.interactor import highlight, nearest_x
from inspect_viz._util.stats import z_score

# read data (see 'Data Preparation' below)
data = Data.from_file("swebench_token_limit.parquet")  # <1>

channels = {             # <6>
    "Token Limit": "total_tokens",
    "Success Rate": "success_rate",
    "Model": "model_display_name",
    "Log": "log_viewer"
}

# convert CI to a z-multiplier
z_alpha = z_score(0.95)    # <5>

# enable interactive highlighting of a chosen model
selection = Selection.single()  # <7>

components = [
    # success-rate lines by model (optionally faceted by difficulty)
    line(                                # <8>
        data, 
        x="total_tokens", 
        y="success_rate", 
        stroke="model_display_name", 
        tip=True, 
        channels=channels
    ),

    # confidence band from mean ± z * stderr
    area_y(                              # <9>
        data,
        x="total_tokens",
        y="success_rate",
        y1=sql(f"success_rate - ({z_alpha} * standard_error)"),
        y2=sql(f"success_rate + ({z_alpha} * standard_error)"),
        color="model_display_name",
        fill="model_display_name",
        fill_opacity=0.3,
        tip=False
    ),


    # interactions: snap by nearest x and highlight selection
    nearest_x(target=selection, channels=["color"]),  # <10>
    highlight(by=selection, opacity=0.2, fill_opacity=0.1),  # <10>
]

plot(
    components,
    x_label="total_tokens",                 # <11>
    y_label="Success rate",    # <11>
    legend=legend("color"),
    x_scale="log",             # <12>
    # layout tweaks
    y_inset_top=10,            # <13>
    margin_bottom=30,          # <13>
    # dimensions
    width=700,                 # <14> (height defaults to width / 1.618)
)
```

1. **Load data** from a Parquet file into an `inspect_viz.Data` table.
2. **Map axes**: `token_limit` on the x‑axis (budget) and `success_rate` on the y‑axis.
3. **Facet** by `difficulty` to compare curves across task difficulty levels.
4. **Color** series by `model_id` so each model has its own line and legend entry.
5. **Confidence interval**: choose a value like `0.80`, `0.90`, or `0.95`; it’s converted to a z‑score for the shaded band.
6. **Channels** provide readable names for tooltips and the log viewer.
7. **Selection** enables interactive hovering/clicking to emphasize a single model.
8. **`line()` mark** draws success‑rate curves with tooltips.
9. **`area_y()`** adds a CI band using `mean ± z * stderr` if `standard_error` is present.
10. **Interactions**: `nearest_x()` snaps the selection to the closest x, and `highlight()` dims the rest.
11. **Labels**: x uses the field name; y is set explicitly (pass `None` to hide).
12. **Log scale** for the budget axis to better separate small and large limits.
13. **Layout**: small top inset avoids clipping; extra bottom margin leaves room for the legend.
14. **Size**: default width is 700px; height defaults to the golden ratio (`width / 1.618`).

## Data preparation

The data dataset for this example was created using the `scores_by_limit_df` function, which reads per-sample metadata, computes token usage, and aggregates a success rate as a function of a limit threshhold. 

{{< include ../../../_data_preparation_scores_by_limit.md >}}
score